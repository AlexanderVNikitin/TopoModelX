{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Hypergraph Neural Network\n",
    "\n",
    "In this notebook, we will create and train a two-step message passing network in the hypergraph domain. We will use a benchmark dataset, shrec16, a collection of 3D meshes, to train the model to perform classification at the level of the hypergraph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T16:14:51.222779223Z",
     "start_time": "2023-06-01T16:14:49.575421023Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from toponetx import SimplicialComplex\n",
    "import toponetx.datasets as datasets\n",
    "from topomodelx.nn.hypergraph.allsettransformer_layer import AllSetTransformerLayer, MultiHeadAttention\n",
    "\n",
    "import torch\n",
    "from torch_geometric.utils import to_edge_index\n",
    "# make ipynb to read .py files continiously\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If GPU's are available, we will make use of them. Otherwise, this will run on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T16:14:51.959770754Z",
     "start_time": "2023-06-01T16:14:51.956096841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import data ##\n",
    "\n",
    "The first step is to import the dataset, shrec 16, a benchmark dataset for 3D mesh classification. We then lift each graph into our domain of choice, a hypergraph.\n",
    "\n",
    "We will also retrieve:\n",
    "- input signal on the edges for each of these hypergraphs, as that will be what we feed the model in input\n",
    "- the label associated to the hypergraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T16:14:53.022151550Z",
     "start_time": "2023-06-01T16:14:52.949636599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "shrec, _ = datasets.mesh.shrec_16(size=\"small\")\n",
    "\n",
    "shrec = {key: np.array(value) for key, value in shrec.items()}\n",
    "x_0s = shrec[\"node_feat\"]\n",
    "x_1s = shrec[\"edge_feat\"]\n",
    "x_2s = shrec[\"face_feat\"]\n",
    "\n",
    "ys = shrec[\"label\"]\n",
    "simplexes = shrec[\"complexes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 6th simplicial complex has 252 nodes with features of dimension 6.\n",
      "The 6th simplicial complex has 750 edges with features of dimension 10.\n",
      "The 6th simplicial complex has 500 faces with features of dimension 7.\n"
     ]
    }
   ],
   "source": [
    "i_complex = 6\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_0s[i_complex].shape[0]} nodes with features of dimension {x_0s[i_complex].shape[1]}.\"\n",
    ")\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_1s[i_complex].shape[0]} edges with features of dimension {x_1s[i_complex].shape[1]}.\"\n",
    ")\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_2s[i_complex].shape[0]} faces with features of dimension {x_2s[i_complex].shape[1]}.\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define neighborhood structures and lift into hypergraph domain. ##\n",
    "\n",
    "Now we retrieve the neighborhood structures (i.e. their representative matrices) that we will use to send messges on each simplicial complex. In the case of this architecture, we need the boundary matrix (or incidence matrix) $B_1$ with shape $n_\\text{nodes} \\times n_\\text{edges}$.\n",
    "\n",
    "Once we have recorded the incidence matrix (note that all incidence amtrices in the hypergraph domain must be unsigned), we lift each simplicial complex into a hypergraph. The pairwise edges will become pairwise hyperedges, and faces in the simplciial complex will become 3-wise hyperedges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T16:14:53.022151550Z",
     "start_time": "2023-06-01T16:14:52.949636599Z"
    }
   },
   "outputs": [],
   "source": [
    "hg_list = []\n",
    "incidence_1_list = []\n",
    "for simplex in simplexes:\n",
    "    incidence_1 = simplex.incidence_matrix(rank=1, signed=False)\n",
    "    # incidence_1 = torch.from_numpy(incidence_1.todense()).to_sparse()\n",
    "    # incidence_1_list.append(incidence_1)\n",
    "    hg = simplex.to_hypergraph()\n",
    "    hg_list.append(hg)\n",
    "\n",
    "\n",
    "# Extract hypergraphs incident matrices from collected hypergraphs\n",
    "for hg in hg_list:\n",
    "    incidence_1 = hg.incidence_matrix()\n",
    "    incidence_1 = torch.from_numpy(incidence_1.todense()).to_sparse()\n",
    "    incidence_1_list.append(incidence_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 6th hypergraph has an incidence matrix of shape torch.Size([252, 1250]).\n"
     ]
    }
   ],
   "source": [
    "i_complex = 6\n",
    "print(\n",
    "    f\"The {i_complex}th hypergraph has an incidence matrix of shape {incidence_1_list[i_complex].shape}.\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Neural Network\n",
    "\n",
    "Using the TemplateLayer class, we create a neural network with stacked layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T16:14:55.343005145Z",
     "start_time": "2023-06-01T16:14:55.339481459Z"
    }
   },
   "outputs": [],
   "source": [
    "channels_edge = x_1s[0].shape[1]\n",
    "channels_node = x_0s[0].shape[1]\n",
    "hid_dim, out_dim = 16, 1\n",
    "\n",
    "in_channels = channels_node\n",
    "out_channels = 1\n",
    "hidden_channels = 16\n",
    "num_heads = 3\n",
    "att_dim = 2\n",
    "x_0 = torch.tensor(x_0s[0], dtype=torch.float32)\n",
    "incidence_1 = incidence_1_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AllSetTransformerConv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m layer \u001b[39m=\u001b[39m AllSetTransformerLayer(\n\u001b[1;32m      2\u001b[0m     channels_node,\n\u001b[1;32m      3\u001b[0m     hid_dim,\n\u001b[1;32m      4\u001b[0m     out_dim,\n\u001b[1;32m      5\u001b[0m     heads\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Cambridge/TopoModelX/topomodelx/nn/hypergraph/allsettransformer_layer.py:52\u001b[0m, in \u001b[0;36mAllSetTransformerLayer.__init__\u001b[0;34m(self, in_channels, hidden_channels, out_channels, dropout, heads, att_dropout)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39massert\u001b[39;00m heads \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mAllSetTransformer requires heads to be specified.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout \u001b[39m=\u001b[39m dropout\n\u001b[0;32m---> 52\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv2e \u001b[39m=\u001b[39m AllSetTransformerConv(\n\u001b[1;32m     53\u001b[0m     in_channels\u001b[39m=\u001b[39min_channels,\n\u001b[1;32m     54\u001b[0m     hidden_channels\u001b[39m=\u001b[39mhidden_channels,\n\u001b[1;32m     55\u001b[0m     out_channels\u001b[39m=\u001b[39mhidden_channels,\n\u001b[1;32m     56\u001b[0m     att_dropout\u001b[39m=\u001b[39matt_dropout,\n\u001b[1;32m     57\u001b[0m     att\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     58\u001b[0m     heads\u001b[39m=\u001b[39mheads,\n\u001b[1;32m     59\u001b[0m )\n\u001b[1;32m     61\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39me2v \u001b[39m=\u001b[39m AllSetTransformerConv(\n\u001b[1;32m     62\u001b[0m     in_channels\u001b[39m=\u001b[39mhidden_channels,\n\u001b[1;32m     63\u001b[0m     hidden_channels\u001b[39m=\u001b[39mhidden_channels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m     heads\u001b[39m=\u001b[39mheads,\n\u001b[1;32m     68\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AllSetTransformerConv' is not defined"
     ]
    }
   ],
   "source": [
    "layer = AllSetTransformerLayer(channels_node, hid_dim, out_dim, heads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = layer(x_0, incidence_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([252, 2])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[   0,    1,    2,  ..., 1247, 1248, 1249],\n",
       "                       [   0,    0,    0,  ...,  251,  251,  251]]),\n",
       "       values=tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
       "       size=(1250, 252), nnz=3000, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incidence_1.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[   0,    0,    0,  ...,  251,  251,  251],\n",
       "                       [   0,    1,    2,  ..., 1247, 1248, 1249]]),\n",
       "       values=tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
       "       size=(252, 1250), nnz=3000, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incidence_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hypergraph({'e0': [0, 1], 'e1': [0, 2], 'e2': [0, 3], 'e3': [0, 5], 'e4': [0, 10], 'e5': [1, 2], 'e6': [1, 3], 'e7': [1, 4], 'e8': [1, 6], 'e9': [2, 5], 'e10': [2, 6], 'e11': [2, 7], 'e12': [3, 4], 'e13': [4, 6], 'e14': [5, 7], 'e15': [5, 37], 'e16': [6, 7], 'e17': [7, 31], 'e18': [8, 13], 'e19': [8, 14], 'e20': [8, 19], 'e21': [8, 20], 'e22': [8, 29], 'e23': [8, 40], 'e24': [9, 4], 'e25': [9, 6], 'e26': [9, 7], 'e27': [9, 10], 'e28': [9, 22], 'e29': [9, 35], 'e30': [10, 3], 'e31': [10, 4], 'e32': [10, 5], 'e33': [10, 22], 'e34': [10, 37], 'e35': [10, 59], 'e36': [11, 5], 'e37': [11, 7], 'e38': [11, 31], 'e39': [11, 37], 'e40': [12, 13], 'e41': [12, 14], 'e42': [12, 44], 'e43': [13, 14], 'e44': [13, 29], 'e45': [14, 23], 'e46': [16, 15], 'e47': [16, 17], 'e48': [16, 18], 'e49': [16, 27], 'e50': [16, 34], 'e51': [17, 27], 'e52': [17, 34], 'e53': [17, 41], 'e54': [17, 63], 'e55': [18, 15], 'e56': [18, 21], 'e57': [18, 27], 'e58': [18, 30], 'e59': [18, 46], 'e60': [18, 53], 'e61': [19, 20], 'e62': [19, 60], 'e63': [19, 77], 'e64': [20, 14], 'e65': [20, 23], 'e66': [20, 45], 'e67': [20, 47], 'e68': [21, 15], 'e69': [21, 46], 'e70': [24, 12], 'e71': [24, 13], 'e72': [24, 25], 'e73': [24, 29], 'e74': [24, 44], 'e75': [24, 46], 'e76': [24, 75], 'e77': [25, 21], 'e78': [25, 26], 'e79': [25, 29], 'e80': [25, 46], 'e81': [26, 21], 'e82': [26, 28], 'e83': [26, 29], 'e84': [26, 38], 'e85': [27, 30], 'e86': [27, 43], 'e87': [28, 21], 'e88': [28, 38], 'e89': [28, 39], 'e90': [32, 12], 'e91': [32, 14], 'e92': [32, 23], 'e93': [32, 44], 'e94': [32, 51], 'e95': [32, 56], 'e96': [33, 19], 'e97': [33, 20], 'e98': [33, 44], 'e99': [33, 45], 'e100': [33, 60], 'e101': [33, 62], 'e102': [34, 15], 'e103': [34, 42], 'e104': [34, 63], 'e105': [35, 7], 'e106': [35, 22], 'e107': [35, 36], 'e108': [36, 7], 'e109': [36, 30], 'e110': [36, 31], 'e111': [36, 71], 'e112': [37, 61], 'e113': [38, 39], 'e114': [39, 63], 'e115': [40, 19], 'e116': [40, 26], 'e117': [40, 29], 'e118': [40, 38], 'e119': [40, 73], 'e120': [40, 77], 'e121': [41, 27], 'e122': [41, 57], 'e123': [41, 63], 'e124': [41, 69], 'e125': [42, 15], 'e126': [42, 21], 'e127': [42, 28], 'e128': [42, 39], 'e129': [42, 63], 'e130': [43, 30], 'e131': [43, 31], 'e132': [43, 36], 'e133': [43, 54], 'e134': [44, 45], 'e135': [44, 52], 'e136': [44, 62], 'e137': [45, 47], 'e138': [45, 55], 'e139': [47, 55], 'e140': [48, 22], 'e141': [48, 59], 'e142': [48, 64], 'e143': [48, 66], 'e144': [49, 11], 'e145': [49, 31], 'e146': [49, 37], 'e147': [49, 43], 'e148': [49, 54], 'e149': [49, 61], 'e150': [50, 20], 'e151': [50, 23], 'e152': [50, 47], 'e153': [50, 58], 'e154': [51, 44], 'e155': [51, 52], 'e156': [52, 45], 'e157': [52, 55], 'e158': [53, 30], 'e159': [53, 46], 'e160': [53, 87], 'e161': [54, 95], 'e162': [56, 23], 'e163': [56, 50], 'e164': [56, 51], 'e165': [56, 52], 'e166': [56, 58], 'e167': [57, 27], 'e168': [57, 43], 'e169': [57, 54], 'e170': [58, 47], 'e171': [58, 52], 'e172': [58, 55], 'e173': [59, 22], 'e174': [59, 37], 'e175': [59, 61], 'e176': [59, 85], 'e177': [59, 91], 'e178': [60, 62], 'e179': [60, 77], 'e180': [61, 54], 'e181': [61, 85], 'e182': [62, 70], 'e183': [64, 59], 'e184': [64, 66], 'e185': [64, 82], 'e186': [64, 91], 'e187': [65, 41], 'e188': [65, 54], 'e189': [65, 57], 'e190': [65, 69], 'e191': [65, 79], 'e192': [65, 89], 'e193': [66, 22], 'e194': [66, 35], 'e195': [66, 36], 'e196': [66, 71], 'e197': [66, 82], 'e198': [67, 30], 'e199': [67, 36], 'e200': [67, 53], 'e201': [67, 71], 'e202': [68, 38], 'e203': [68, 39], 'e204': [68, 84], 'e205': [68, 109], 'e206': [69, 63], 'e207': [69, 78], 'e208': [69, 79], 'e209': [70, 94], 'e210': [72, 60], 'e211': [72, 62], 'e212': [72, 70], 'e213': [72, 76], 'e214': [72, 77], 'e215': [72, 93], 'e216': [72, 100], 'e217': [73, 38], 'e218': [73, 74], 'e219': [73, 77], 'e220': [73, 81], 'e221': [74, 38], 'e222': [74, 68], 'e223': [74, 106], 'e224': [74, 117], 'e225': [75, 44], 'e226': [75, 46], 'e227': [75, 53], 'e228': [75, 62], 'e229': [75, 70], 'e230': [75, 87], 'e231': [75, 94], 'e232': [76, 77], 'e233': [76, 93], 'e234': [76, 101], 'e235': [76, 110], 'e236': [78, 39], 'e237': [78, 63], 'e238': [78, 79], 'e239': [80, 53], 'e240': [80, 67], 'e241': [80, 87], 'e242': [80, 90], 'e243': [80, 96], 'e244': [81, 74], 'e245': [81, 76], 'e246': [81, 77], 'e247': [81, 110], 'e248': [81, 117], 'e249': [82, 71], 'e250': [82, 83], 'e251': [82, 91], 'e252': [83, 71], 'e253': [83, 91], 'e254': [84, 39], 'e255': [84, 78], 'e256': [84, 109], 'e257': [85, 54], 'e258': [85, 86], 'e259': [85, 95], 'e260': [86, 95], 'e261': [88, 79], 'e262': [88, 89], 'e263': [88, 92], 'e264': [88, 115], 'e265': [88, 123], 'e266': [89, 54], 'e267': [89, 79], 'e268': [89, 95], 'e269': [89, 111], 'e270': [89, 115], 'e271': [90, 87], 'e272': [90, 99], 'e273': [91, 85], 'e274': [91, 86], 'e275': [91, 108], 'e276': [92, 79], 'e277': [93, 101], 'e278': [94, 87], 'e279': [94, 102], 'e280': [95, 111], 'e281': [96, 67], 'e282': [96, 71], 'e283': [96, 83], 'e284': [96, 90], 'e285': [96, 98], 'e286': [96, 105], 'e287': [96, 112], 'e288': [97, 78], 'e289': [97, 79], 'e290': [97, 84], 'e291': [97, 92], 'e292': [97, 107], 'e293': [98, 83], 'e294': [98, 91], 'e295': [98, 103], 'e296': [98, 108], 'e297': [99, 87], 'e298': [99, 94], 'e299': [99, 102], 'e300': [100, 70], 'e301': [100, 93], 'e302': [100, 94], 'e303': [100, 101], 'e304': [100, 102], 'e305': [101, 102], 'e306': [101, 110], 'e307': [102, 118], 'e308': [104, 99], 'e309': [104, 102], 'e310': [104, 112], 'e311': [104, 118], 'e312': [104, 119], 'e313': [104, 120], 'e314': [105, 98], 'e315': [105, 103], 'e316': [105, 116], 'e317': [105, 119], 'e318': [106, 68], 'e319': [106, 109], 'e320': [106, 117], 'e321': [106, 124], 'e322': [106, 134], 'e323': [107, 84], 'e324': [107, 92], 'e325': [107, 109], 'e326': [107, 123], 'e327': [107, 124], 'e328': [107, 132], 'e329': [108, 86], 'e330': [108, 95], 'e331': [108, 103], 'e332': [108, 126], 'e333': [112, 90], 'e334': [112, 99], 'e335': [112, 105], 'e336': [112, 119], 'e337': [113, 101], 'e338': [113, 102], 'e339': [113, 110], 'e340': [113, 118], 'e341': [113, 121], 'e342': [113, 122], 'e343': [114, 95], 'e344': [114, 108], 'e345': [114, 111], 'e346': [114, 115], 'e347': [114, 123], 'e348': [114, 125], 'e349': [114, 126], 'e350': [114, 127], 'e351': [115, 111], 'e352': [115, 123], 'e353': [116, 103], 'e354': [116, 119], 'e355': [116, 126], 'e356': [117, 110], 'e357': [117, 134], 'e358': [120, 118], 'e359': [120, 119], 'e360': [120, 121], 'e361': [120, 133], 'e362': [120, 135], 'e363': [120, 136], 'e364': [121, 118], 'e365': [121, 122], 'e366': [121, 130], 'e367': [121, 135], 'e368': [122, 110], 'e369': [122, 117], 'e370': [122, 130], 'e371': [122, 138], 'e372': [123, 92], 'e373': [123, 127], 'e374': [123, 132], 'e375': [124, 109], 'e376': [124, 132], 'e377': [124, 134], 'e378': [124, 140], 'e379': [125, 126], 'e380': [125, 127], 'e381': [126, 103], 'e382': [128, 116], 'e383': [128, 119], 'e384': [128, 126], 'e385': [128, 129], 'e386': [128, 133], 'e387': [128, 137], 'e388': [129, 126], 'e389': [129, 131], 'e390': [129, 137], 'e391': [129, 156], 'e392': [130, 135], 'e393': [130, 138], 'e394': [130, 143], 'e395': [131, 125], 'e396': [131, 126], 'e397': [131, 156], 'e398': [131, 195], 'e399': [132, 127], 'e400': [132, 140], 'e401': [133, 119], 'e402': [135, 143], 'e403': [136, 133], 'e404': [136, 135], 'e405': [136, 142], 'e406': [136, 145], 'e407': [136, 150], 'e408': [137, 133], 'e409': [137, 139], 'e410': [137, 156], 'e411': [138, 117], 'e412': [138, 134], 'e413': [138, 143], 'e414': [138, 155], 'e415': [139, 133], 'e416': [139, 163], 'e417': [140, 134], 'e418': [140, 175], 'e419': [141, 158], 'e420': [141, 159], 'e421': [142, 150], 'e422': [142, 151], 'e423': [144, 127], 'e424': [144, 132], 'e425': [144, 140], 'e426': [144, 153], 'e427': [144, 175], 'e428': [144, 201], 'e429': [145, 133], 'e430': [145, 142], 'e431': [145, 146], 'e432': [146, 133], 'e433': [146, 139], 'e434': [146, 182], 'e435': [146, 189], 'e436': [146, 190], 'e437': [147, 149], 'e438': [147, 157], 'e439': [147, 165], 'e440': [148, 141], 'e441': [148, 159], 'e442': [148, 197], 'e443': [149, 157], 'e444': [150, 135], 'e445': [150, 143], 'e446': [152, 142], 'e447': [152, 145], 'e448': [152, 146], 'e449': [152, 151], 'e450': [152, 171], 'e451': [152, 180], 'e452': [152, 182], 'e453': [153, 125], 'e454': [153, 127], 'e455': [153, 131], 'e456': [153, 201], 'e457': [154, 141], 'e458': [154, 148], 'e459': [154, 158], 'e460': [155, 134], 'e461': [155, 140], 'e462': [155, 143], 'e463': [155, 203], 'e464': [156, 166], 'e465': [157, 165], 'e466': [157, 207], 'e467': [160, 137], 'e468': [160, 139], 'e469': [160, 156], 'e470': [160, 163], 'e471': [160, 166], 'e472': [160, 187], 'e473': [161, 139], 'e474': [161, 146], 'e475': [161, 163], 'e476': [161, 167], 'e477': [161, 174], 'e478': [161, 189], 'e479': [162, 154], 'e480': [162, 158], 'e481': [162, 170], 'e482': [162, 173], 'e483': [162, 215], 'e484': [163, 174], 'e485': [163, 187], 'e486': [164, 142], 'e487': [164, 150], 'e488': [164, 151], 'e489': [164, 181], 'e490': [165, 207], 'e491': [167, 183], 'e492': [168, 149], 'e493': [168, 157], 'e494': [168, 194], 'e495': [168, 221], 'e496': [169, 140], 'e497': [169, 155], 'e498': [169, 175], 'e499': [169, 201], 'e500': [169, 203], 'e501': [169, 212], 'e502': [169, 218], 'e503': [169, 221], 'e504': [169, 234], 'e505': [170, 148], 'e506': [170, 154], 'e507': [170, 197], 'e508': [170, 204], 'e509': [170, 215], 'e510': [170, 228], 'e511': [171, 151], 'e512': [171, 172], 'e513': [171, 179], 'e514': [171, 180], 'e515': [171, 188], 'e516': [172, 151], 'e517': [172, 181], 'e518': [172, 199], 'e519': [173, 158], 'e520': [173, 215], 'e521': [173, 223], 'e522': [174, 167], 'e523': [174, 198], 'e524': [174, 222], 'e525': [176, 141], 'e526': [176, 158], 'e527': [176, 159], 'e528': [176, 197], 'e529': [176, 204], 'e530': [176, 208], 'e531': [177, 143], 'e532': [177, 178], 'e533': [177, 186], 'e534': [177, 206], 'e535': [177, 225], 'e536': [177, 237], 'e537': [178, 143], 'e538': [178, 150], 'e539': [178, 164], 'e540': [178, 181], 'e541': [178, 186], 'e542': [178, 199], 'e543': [179, 172], 'e544': [180, 182], 'e545': [180, 188], 'e546': [180, 206], 'e547': [181, 151], 'e548': [181, 199], 'e549': [182, 206], 'e550': [183, 191], 'e551': [184, 143], 'e552': [184, 155], 'e553': [184, 177], 'e554': [184, 203], 'e555': [184, 212], 'e556': [184, 237], 'e557': [185, 163], 'e558': [185, 174], 'e559': [185, 187], 'e560': [185, 191], 'e561': [185, 198], 'e562': [185, 222], 'e563': [186, 206], 'e564': [187, 166], 'e565': [187, 191], 'e566': [187, 196], 'e567': [187, 205], 'e568': [188, 199], 'e569': [189, 167], 'e570': [189, 183], 'e571': [189, 190], 'e572': [192, 166], 'e573': [192, 187], 'e574': [192, 195], 'e575': [192, 205], 'e576': [192, 213], 'e577': [193, 178], 'e578': [193, 180], 'e579': [193, 186], 'e580': [193, 188], 'e581': [193, 199], 'e582': [193, 206], 'e583': [194, 157], 'e584': [194, 207], 'e585': [194, 214], 'e586': [194, 221], 'e587': [195, 156], 'e588': [195, 166], 'e589': [195, 213], 'e590': [195, 227], 'e591': [196, 183], 'e592': [196, 189], 'e593': [196, 190], 'e594': [196, 191], 'e595': [196, 205], 'e596': [197, 159], 'e597': [198, 222], 'e598': [200, 172], 'e599': [200, 179], 'e600': [200, 199], 'e601': [200, 202], 'e602': [200, 219], 'e603': [201, 131], 'e604': [201, 173], 'e605': [201, 175], 'e606': [201, 215], 'e607': [201, 218], 'e608': [201, 223], 'e609': [202, 171], 'e610': [202, 179], 'e611': [202, 188], 'e612': [202, 219], 'e613': [203, 212], 'e614': [204, 197], 'e615': [204, 228], 'e616': [205, 190], 'e617': [205, 213], 'e618': [208, 158], 'e619': [208, 173], 'e620': [208, 204], 'e621': [208, 223], 'e622': [208, 228], 'e623': [209, 146], 'e624': [209, 182], 'e625': [209, 190], 'e626': [209, 205], 'e627': [209, 206], 'e628': [209, 213], 'e629': [209, 226], 'e630': [210, 165], 'e631': [210, 211], 'e632': [210, 218], 'e633': [210, 221], 'e634': [210, 223], 'e635': [211, 165], 'e636': [211, 207], 'e637': [211, 214], 'e638': [211, 223], 'e639': [211, 228], 'e640': [212, 237], 'e641': [214, 207], 'e642': [214, 230], 'e643': [215, 231], 'e644': [216, 170], 'e645': [216, 215], 'e646': [216, 228], 'e647': [216, 229], 'e648': [216, 231], 'e649': [217, 147], 'e650': [217, 149], 'e651': [217, 165], 'e652': [217, 210], 'e653': [217, 221], 'e654': [218, 221], 'e655': [218, 223], 'e656': [219, 188], 'e657': [219, 199], 'e658': [220, 167], 'e659': [220, 174], 'e660': [220, 183], 'e661': [220, 191], 'e662': [220, 222], 'e663': [221, 149], 'e664': [221, 214], 'e665': [221, 230], 'e666': [222, 191], 'e667': [224, 131], 'e668': [224, 195], 'e669': [224, 201], 'e670': [224, 215], 'e671': [224, 227], 'e672': [224, 231], 'e673': [225, 206], 'e674': [225, 226], 'e675': [225, 233], 'e676': [225, 237], 'e677': [226, 206], 'e678': [226, 213], 'e679': [226, 235], 'e680': [226, 239], 'e681': [227, 213], 'e682': [227, 231], 'e683': [227, 235], 'e684': [227, 244], 'e685': [227, 246], 'e686': [228, 223], 'e687': [228, 229], 'e688': [229, 231], 'e689': [229, 238], 'e690': [232, 211], 'e691': [232, 214], 'e692': [232, 228], 'e693': [232, 229], 'e694': [232, 230], 'e695': [232, 236], 'e696': [232, 238], 'e697': [233, 226], 'e698': [233, 237], 'e699': [233, 239], 'e700': [233, 241], 'e701': [234, 212], 'e702': [234, 221], 'e703': [234, 230], 'e704': [234, 237], 'e705': [234, 242], 'e706': [234, 243], 'e707': [235, 213], 'e708': [235, 239], 'e709': [235, 246], 'e710': [236, 230], 'e711': [236, 238], 'e712': [240, 229], 'e713': [240, 231], 'e714': [240, 238], 'e715': [240, 244], 'e716': [240, 248], 'e717': [240, 250], 'e718': [241, 234], 'e719': [241, 237], 'e720': [241, 239], 'e721': [241, 243], 'e722': [241, 245], 'e723': [241, 251], 'e724': [242, 230], 'e725': [242, 236], 'e726': [242, 238], 'e727': [242, 243], 'e728': [242, 247], 'e729': [243, 247], 'e730': [243, 251], 'e731': [244, 231], 'e732': [245, 239], 'e733': [245, 246], 'e734': [246, 239], 'e735': [248, 238], 'e736': [248, 242], 'e737': [248, 247], 'e738': [248, 250], 'e739': [249, 227], 'e740': [249, 244], 'e741': [249, 245], 'e742': [249, 246], 'e743': [249, 247], 'e744': [249, 250], 'e745': [249, 251], 'e746': [250, 244], 'e747': [250, 247], 'e748': [251, 245], 'e749': [251, 247], 'e750': [0, 1, 2], 'e751': [0, 1, 3], 'e752': [0, 2, 5], 'e753': [0, 10, 3], 'e754': [0, 10, 5], 'e755': [1, 2, 6], 'e756': [1, 3, 4], 'e757': [1, 4, 6], 'e758': [2, 5, 7], 'e759': [2, 6, 7], 'e760': [5, 11, 37], 'e761': [8, 13, 14], 'e762': [8, 13, 29], 'e763': [8, 19, 20], 'e764': [8, 20, 14], 'e765': [8, 40, 19], 'e766': [8, 40, 29], 'e767': [9, 4, 6], 'e768': [9, 6, 7], 'e769': [9, 10, 4], 'e770': [9, 10, 22], 'e771': [9, 35, 7], 'e772': [9, 35, 22], 'e773': [10, 3, 4], 'e774': [10, 5, 37], 'e775': [10, 59, 22], 'e776': [10, 59, 37], 'e777': [11, 5, 7], 'e778': [11, 7, 31], 'e779': [12, 13, 14], 'e780': [16, 17, 27], 'e781': [16, 17, 34], 'e782': [16, 18, 15], 'e783': [16, 18, 27], 'e784': [16, 34, 15], 'e785': [17, 27, 41], 'e786': [17, 34, 63], 'e787': [17, 41, 63], 'e788': [18, 21, 15], 'e789': [18, 21, 46], 'e790': [18, 27, 30], 'e791': [18, 53, 30], 'e792': [18, 53, 46], 'e793': [19, 60, 77], 'e794': [20, 14, 23], 'e795': [20, 45, 47], 'e796': [24, 12, 13], 'e797': [24, 12, 44], 'e798': [24, 13, 29], 'e799': [24, 25, 29], 'e800': [24, 25, 46], 'e801': [24, 75, 44], 'e802': [24, 75, 46], 'e803': [25, 21, 46], 'e804': [25, 26, 21], 'e805': [25, 26, 29], 'e806': [26, 28, 21], 'e807': [26, 28, 38], 'e808': [27, 43, 30], 'e809': [27, 57, 43], 'e810': [28, 38, 39], 'e811': [32, 12, 14], 'e812': [32, 12, 44], 'e813': [32, 14, 23], 'e814': [32, 51, 44], 'e815': [32, 56, 23], 'e816': [32, 56, 51], 'e817': [33, 19, 20], 'e818': [33, 19, 60], 'e819': [33, 20, 45], 'e820': [33, 44, 45], 'e821': [33, 44, 62], 'e822': [33, 60, 62], 'e823': [34, 42, 15], 'e824': [34, 42, 63], 'e825': [35, 36, 7], 'e826': [36, 7, 31], 'e827': [37, 59, 61], 'e828': [39, 78, 63], 'e829': [40, 19, 77], 'e830': [40, 26, 29], 'e831': [40, 26, 38], 'e832': [40, 73, 38], 'e833': [40, 73, 77], 'e834': [41, 27, 57], 'e835': [41, 69, 63], 'e836': [42, 21, 15], 'e837': [42, 28, 21], 'e838': [42, 28, 39], 'e839': [42, 39, 63], 'e840': [43, 36, 30], 'e841': [43, 36, 31], 'e842': [44, 45, 52], 'e843': [47, 45, 55], 'e844': [48, 59, 22], 'e845': [48, 59, 64], 'e846': [48, 66, 22], 'e847': [48, 66, 64], 'e848': [49, 11, 31], 'e849': [49, 11, 37], 'e850': [49, 37, 61], 'e851': [49, 43, 31], 'e852': [49, 43, 54], 'e853': [49, 61, 54], 'e854': [50, 20, 23], 'e855': [50, 20, 47], 'e856': [50, 58, 47], 'e857': [51, 44, 52], 'e858': [52, 45, 55], 'e859': [56, 50, 23], 'e860': [56, 50, 58], 'e861': [56, 51, 52], 'e862': [56, 58, 52], 'e863': [57, 43, 54], 'e864': [58, 47, 55], 'e865': [58, 52, 55], 'e866': [59, 91, 85], 'e867': [61, 59, 85], 'e868': [61, 85, 54], 'e869': [62, 75, 70], 'e870': [64, 59, 91], 'e871': [64, 66, 82], 'e872': [64, 82, 91], 'e873': [65, 54, 57], 'e874': [65, 57, 41], 'e875': [65, 69, 41], 'e876': [65, 69, 79], 'e877': [65, 89, 54], 'e878': [65, 89, 79], 'e879': [66, 35, 22], 'e880': [66, 35, 36], 'e881': [66, 36, 71], 'e882': [66, 82, 71], 'e883': [67, 36, 30], 'e884': [67, 36, 71], 'e885': [67, 53, 30], 'e886': [68, 38, 39], 'e887': [68, 39, 84], 'e888': [68, 109, 84], 'e889': [69, 78, 63], 'e890': [69, 78, 79], 'e891': [70, 75, 94], 'e892': [70, 100, 94], 'e893': [72, 60, 62], 'e894': [72, 60, 77], 'e895': [72, 62, 70], 'e896': [72, 76, 77], 'e897': [72, 76, 93], 'e898': [72, 100, 70], 'e899': [72, 100, 93], 'e900': [73, 74, 38], 'e901': [73, 81, 74], 'e902': [73, 81, 77], 'e903': [74, 68, 38], 'e904': [74, 68, 106], 'e905': [74, 117, 106], 'e906': [75, 44, 62], 'e907': [75, 53, 46], 'e908': [75, 53, 87], 'e909': [75, 94, 87], 'e910': [76, 101, 110], 'e911': [80, 53, 87], 'e912': [80, 67, 53], 'e913': [80, 67, 96], 'e914': [80, 90, 87], 'e915': [80, 90, 96], 'e916': [81, 74, 117], 'e917': [81, 76, 77], 'e918': [81, 76, 110], 'e919': [81, 117, 110], 'e920': [82, 83, 71], 'e921': [83, 82, 91], 'e922': [83, 91, 98], 'e923': [84, 78, 39], 'e924': [85, 54, 95], 'e925': [85, 86, 95], 'e926': [88, 89, 79], 'e927': [88, 89, 115], 'e928': [88, 92, 79], 'e929': [88, 115, 123], 'e930': [88, 123, 92], 'e931': [89, 54, 95], 'e932': [89, 95, 111], 'e933': [89, 115, 111], 'e934': [90, 99, 87], 'e935': [91, 85, 86], 'e936': [91, 108, 86], 'e937': [93, 76, 101], 'e938': [93, 100, 101], 'e939': [94, 99, 102], 'e940': [94, 100, 102], 'e941': [96, 67, 71], 'e942': [96, 83, 71], 'e943': [96, 90, 112], 'e944': [96, 98, 83], 'e945': [96, 105, 98], 'e946': [96, 105, 112], 'e947': [97, 78, 79], 'e948': [97, 84, 78], 'e949': [97, 92, 79], 'e950': [97, 107, 84], 'e951': [97, 107, 92], 'e952': [98, 91, 108], 'e953': [98, 108, 103], 'e954': [99, 94, 87], 'e955': [100, 101, 102], 'e956': [104, 99, 102], 'e957': [104, 99, 112], 'e958': [104, 102, 118], 'e959': [104, 112, 119], 'e960': [104, 120, 118], 'e961': [104, 120, 119], 'e962': [105, 98, 103], 'e963': [105, 116, 103], 'e964': [105, 116, 119], 'e965': [106, 68, 109], 'e966': [106, 117, 134], 'e967': [106, 124, 109], 'e968': [106, 124, 134], 'e969': [107, 84, 109], 'e970': [107, 123, 92], 'e971': [107, 123, 132], 'e972': [107, 124, 109], 'e973': [108, 86, 95], 'e974': [108, 126, 103], 'e975': [112, 90, 99], 'e976': [112, 105, 119], 'e977': [113, 101, 102], 'e978': [113, 101, 110], 'e979': [113, 102, 118], 'e980': [113, 118, 121], 'e981': [113, 122, 110], 'e982': [113, 122, 121], 'e983': [114, 95, 111], 'e984': [114, 108, 95], 'e985': [114, 108, 126], 'e986': [114, 115, 111], 'e987': [114, 123, 127], 'e988': [114, 125, 126], 'e989': [114, 125, 127], 'e990': [115, 114, 123], 'e991': [116, 126, 103], 'e992': [120, 121, 118], 'e993': [120, 121, 135], 'e994': [120, 133, 119], 'e995': [120, 136, 133], 'e996': [120, 136, 135], 'e997': [121, 122, 130], 'e998': [121, 130, 135], 'e999': [122, 117, 110], 'e1000': [122, 117, 138], 'e1001': [122, 130, 138], 'e1002': [123, 132, 127], 'e1003': [124, 107, 132], 'e1004': [124, 140, 132], 'e1005': [124, 140, 134], 'e1006': [128, 116, 119], 'e1007': [128, 116, 126], 'e1008': [128, 129, 126], 'e1009': [128, 129, 137], 'e1010': [128, 133, 119], 'e1011': [128, 137, 133], 'e1012': [129, 131, 126], 'e1013': [129, 131, 156], 'e1014': [129, 137, 156], 'e1015': [130, 138, 143], 'e1016': [131, 125, 126], 'e1017': [131, 156, 195], 'e1018': [135, 130, 143], 'e1019': [135, 150, 143], 'e1020': [136, 142, 150], 'e1021': [136, 145, 133], 'e1022': [136, 145, 142], 'e1023': [136, 150, 135], 'e1024': [137, 139, 133], 'e1025': [138, 117, 134], 'e1026': [138, 155, 134], 'e1027': [138, 155, 143], 'e1028': [142, 164, 150], 'e1029': [144, 132, 127], 'e1030': [144, 132, 140], 'e1031': [144, 140, 175], 'e1032': [144, 153, 127], 'e1033': [144, 153, 201], 'e1034': [144, 201, 175], 'e1035': [145, 146, 133], 'e1036': [146, 139, 133], 'e1037': [146, 189, 190], 'e1038': [147, 149, 157], 'e1039': [147, 157, 165], 'e1040': [148, 141, 159], 'e1041': [148, 197, 159], 'e1042': [152, 142, 151], 'e1043': [152, 145, 142], 'e1044': [152, 145, 146], 'e1045': [152, 146, 182], 'e1046': [152, 171, 151], 'e1047': [152, 171, 180], 'e1048': [152, 180, 182], 'e1049': [153, 125, 127], 'e1050': [153, 131, 125], 'e1051': [153, 131, 201], 'e1052': [154, 141, 158], 'e1053': [154, 148, 141], 'e1054': [155, 140, 134], 'e1055': [160, 137, 139], 'e1056': [160, 137, 156], 'e1057': [160, 139, 163], 'e1058': [160, 156, 166], 'e1059': [160, 163, 187], 'e1060': [160, 187, 166], 'e1061': [161, 139, 163], 'e1062': [161, 146, 139], 'e1063': [161, 146, 189], 'e1064': [161, 163, 174], 'e1065': [161, 174, 167], 'e1066': [161, 189, 167], 'e1067': [162, 158, 154], 'e1068': [162, 170, 215], 'e1069': [162, 173, 158], 'e1070': [162, 173, 215], 'e1071': [164, 142, 151], 'e1072': [164, 181, 151], 'e1073': [165, 157, 207], 'e1074': [167, 189, 183], 'e1075': [167, 220, 183], 'e1076': [168, 149, 157], 'e1077': [168, 194, 157], 'e1078': [168, 194, 221], 'e1079': [168, 221, 149], 'e1080': [169, 140, 175], 'e1081': [169, 155, 140], 'e1082': [169, 155, 203], 'e1083': [169, 201, 175], 'e1084': [169, 203, 212], 'e1085': [169, 218, 201], 'e1086': [169, 218, 221], 'e1087': [169, 234, 212], 'e1088': [169, 234, 221], 'e1089': [170, 148, 154], 'e1090': [170, 148, 197], 'e1091': [170, 162, 154], 'e1092': [170, 204, 197], 'e1093': [170, 204, 228], 'e1094': [171, 172, 151], 'e1095': [171, 172, 179], 'e1096': [172, 181, 151], 'e1097': [172, 181, 199], 'e1098': [174, 198, 222], 'e1099': [176, 141, 158], 'e1100': [176, 141, 159], 'e1101': [176, 158, 208], 'e1102': [176, 197, 159], 'e1103': [176, 204, 197], 'e1104': [176, 204, 208], 'e1105': [177, 178, 143], 'e1106': [177, 186, 206], 'e1107': [177, 225, 206], 'e1108': [177, 225, 237], 'e1109': [178, 150, 143], 'e1110': [178, 164, 150], 'e1111': [178, 164, 181], 'e1112': [178, 177, 186], 'e1113': [178, 181, 199], 'e1114': [178, 193, 186], 'e1115': [180, 171, 188], 'e1116': [180, 182, 206], 'e1117': [183, 196, 191], 'e1118': [183, 220, 191], 'e1119': [184, 155, 143], 'e1120': [184, 155, 203], 'e1121': [184, 177, 143], 'e1122': [184, 177, 237], 'e1123': [184, 203, 212], 'e1124': [184, 212, 237], 'e1125': [185, 163, 174], 'e1126': [185, 163, 187], 'e1127': [185, 174, 198], 'e1128': [185, 187, 191], 'e1129': [185, 198, 222], 'e1130': [185, 222, 191], 'e1131': [187, 196, 191], 'e1132': [187, 196, 205], 'e1133': [192, 187, 166], 'e1134': [192, 187, 205], 'e1135': [192, 195, 166], 'e1136': [192, 195, 213], 'e1137': [192, 205, 213], 'e1138': [193, 178, 199], 'e1139': [193, 180, 188], 'e1140': [193, 180, 206], 'e1141': [193, 186, 206], 'e1142': [193, 188, 199], 'e1143': [194, 157, 207], 'e1144': [194, 214, 207], 'e1145': [194, 221, 214], 'e1146': [195, 156, 166], 'e1147': [195, 213, 227], 'e1148': [196, 189, 183], 'e1149': [196, 189, 190], 'e1150': [196, 205, 190], 'e1151': [200, 172, 199], 'e1152': [200, 179, 172], 'e1153': [200, 202, 179], 'e1154': [200, 202, 219], 'e1155': [200, 219, 199], 'e1156': [201, 173, 215], 'e1157': [201, 173, 223], 'e1158': [201, 218, 223], 'e1159': [202, 171, 179], 'e1160': [202, 171, 188], 'e1161': [202, 219, 188], 'e1162': [205, 209, 213], 'e1163': [208, 173, 158], 'e1164': [208, 173, 223], 'e1165': [208, 204, 228], 'e1166': [208, 228, 223], 'e1167': [209, 146, 182], 'e1168': [209, 146, 190], 'e1169': [209, 182, 206], 'e1170': [209, 205, 190], 'e1171': [209, 226, 206], 'e1172': [209, 226, 213], 'e1173': [210, 211, 165], 'e1174': [210, 211, 223], 'e1175': [210, 218, 221], 'e1176': [210, 218, 223], 'e1177': [211, 165, 207], 'e1178': [211, 214, 207], 'e1179': [211, 228, 223], 'e1180': [216, 170, 215], 'e1181': [216, 170, 228], 'e1182': [216, 215, 231], 'e1183': [216, 228, 229], 'e1184': [216, 229, 231], 'e1185': [217, 147, 149], 'e1186': [217, 147, 165], 'e1187': [217, 210, 165], 'e1188': [217, 210, 221], 'e1189': [217, 221, 149], 'e1190': [219, 188, 199], 'e1191': [220, 174, 167], 'e1192': [220, 174, 222], 'e1193': [220, 222, 191], 'e1194': [221, 214, 230], 'e1195': [224, 131, 195], 'e1196': [224, 195, 227], 'e1197': [224, 201, 131], 'e1198': [224, 201, 215], 'e1199': [224, 215, 231], 'e1200': [224, 227, 231], 'e1201': [225, 226, 206], 'e1202': [225, 226, 233], 'e1203': [225, 233, 237], 'e1204': [226, 235, 213], 'e1205': [226, 235, 239], 'e1206': [227, 213, 235], 'e1207': [227, 244, 231], 'e1208': [227, 246, 235], 'e1209': [232, 211, 214], 'e1210': [232, 211, 228], 'e1211': [232, 214, 230], 'e1212': [232, 228, 229], 'e1213': [232, 229, 238], 'e1214': [232, 236, 230], 'e1215': [232, 236, 238], 'e1216': [233, 226, 239], 'e1217': [233, 241, 237], 'e1218': [233, 241, 239], 'e1219': [234, 212, 237], 'e1220': [234, 221, 230], 'e1221': [234, 242, 230], 'e1222': [234, 242, 243], 'e1223': [235, 246, 239], 'e1224': [240, 229, 231], 'e1225': [240, 229, 238], 'e1226': [240, 244, 231], 'e1227': [240, 248, 238], 'e1228': [240, 248, 250], 'e1229': [240, 250, 244], 'e1230': [241, 234, 237], 'e1231': [241, 234, 243], 'e1232': [241, 243, 251], 'e1233': [241, 245, 239], 'e1234': [241, 251, 245], 'e1235': [242, 236, 230], 'e1236': [242, 236, 238], 'e1237': [242, 243, 247], 'e1238': [245, 246, 239], 'e1239': [247, 243, 251], 'e1240': [248, 242, 238], 'e1241': [248, 242, 247], 'e1242': [248, 250, 247], 'e1243': [249, 227, 244], 'e1244': [249, 227, 246], 'e1245': [249, 245, 246], 'e1246': [249, 250, 244], 'e1247': [249, 250, 247], 'e1248': [249, 251, 245], 'e1249': [249, 251, 247]},name=)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hg_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.nn.Parameter(torch.ones(num_heads, in_channels, hidden_channels))\n",
    "att_weight = torch.nn.Parameter(torch.randn(num_heads, att_dim, hidden_channels))\n",
    "neighborhood = incidence_1.T.coalesce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_K = torch.transpose(torch.matmul(x_0, K), 1, 2)\n",
    "alpha = torch.matmul(att_weight, x_K).T\n",
    "expanded_alpha = (\n",
    "    torch.sparse_coo_tensor(\n",
    "        indices=neighborhood.indices(),\n",
    "        values=alpha[neighborhood.indices()[1]],\n",
    "        size=[\n",
    "            neighborhood.shape[0],\n",
    "            neighborhood.shape[1],\n",
    "            alpha.shape[1],\n",
    "            alpha.shape[2],\n",
    "        ],\n",
    "    )\n",
    "    .to_dense()\n",
    "    .transpose(1, 3)\n",
    "    .to_sparse()\n",
    ")\n",
    "alpha_soft = torch.sparse.softmax(expanded_alpha, dim=3).to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = torch.nn.Parameter(torch.ones(num_heads, in_channels, hidden_channels))\n",
    "x_V = torch.matmul(x_0, V)\n",
    "x_message = torch.matmul(alpha_soft, x_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0987, 1.0987, 1.0987, 1.0987, 1.0987, 1.0987, 1.0987, 1.0987, 1.0987,\n",
       "         1.0987, 1.0987, 1.0987, 1.0987, 1.0987, 1.0987, 1.0987],\n",
       "        [1.6975, 1.6975, 1.6975, 1.6975, 1.6975, 1.6975, 1.6975, 1.6975, 1.6975,\n",
       "         1.6975, 1.6975, 1.6975, 1.6975, 1.6975, 1.6975, 1.6975]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_message[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6086, 0.3914, 0.0000, 0.0000, 0.0000],\n",
       "         [0.9834, 0.0166, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.2007, 0.7993, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0668, 0.9332, 0.0000, 0.0000, 0.0000]]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_soft[0, 0:2, :, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([252, 2, 3])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 252, 16])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([252, 2, 3])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 252])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1250, 3, 2, 252])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1250, 3, 2, 252])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_soft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiheadatt = MultiHeadAttention(in_channels, hidden_channels, out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1250, 4, 1, 16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiheadatt(x_0, incidence_1.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[   0,    0,    1,  ..., 1249, 1249, 1249],\n",
       "                       [   0,    1,    0,  ...,  249,  250,  251]]),\n",
       "       values=tensor([[[-6.5605,  2.0592, -0.2525],\n",
       "                       [ 5.8235,  0.2112, -3.0831]],\n",
       "\n",
       "                      [[-0.4819,  0.1513, -0.0185],\n",
       "                       [ 0.4278,  0.0155, -0.2265]],\n",
       "\n",
       "                      [[-6.5605,  2.0592, -0.2525],\n",
       "                       [ 5.8235,  0.2112, -3.0831]],\n",
       "\n",
       "                      ...,\n",
       "\n",
       "                      [[ 3.7883, -1.1891,  0.1458],\n",
       "                       [-3.3628, -0.1220,  1.7803]],\n",
       "\n",
       "                      [[ 1.4999, -0.4708,  0.0577],\n",
       "                       [-1.3314, -0.0483,  0.7049]],\n",
       "\n",
       "                      [[ 8.1698, -2.5643,  0.3144],\n",
       "                       [-7.2520, -0.2630,  3.8394]]]),\n",
       "       size=(1250, 252, 2, 3), nnz=3000, layout=torch.sparse_coo,\n",
       "       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[   0,    0,    1,  ..., 1249, 1249, 1249],\n",
       "                       [   0,    1,    0,  ...,  249,  250,  251]]),\n",
       "       values=tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
       "       size=(1250, 252), nnz=3000, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000, 2, 3])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha[layer.v2e.source_index_j].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T16:14:56.033274119Z",
     "start_time": "2023-06-01T16:14:56.029056913Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword argument repeated: mlp_num_layers (1351336644.py, line 46)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 46\u001b[0;36m\u001b[0m\n\u001b[0;31m    mlp_num_layers=2,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword argument repeated: mlp_num_layers\n"
     ]
    }
   ],
   "source": [
    "class AllSetNN(torch.nn.Module):\n",
    "    \"\"\"AllSet Neural Network Module.\n",
    "\n",
    "    A module that combines multiple AllSet layers to form a neural network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_dim : int\n",
    "        Dimension of the input features.\n",
    "    hid_dim : int\n",
    "        Dimension of the hidden features.\n",
    "    out_dim : int\n",
    "        Dimension of the output features.\n",
    "    dropout : float\n",
    "        Dropout probability.\n",
    "    n_layers : int, optional\n",
    "        Number of AllSet layers in the network. Defaults to 2.\n",
    "    input_dropout : float, optional\n",
    "        Dropout probability for the layer input. Defaults to 0.2.\n",
    "    mlp_num_layers : int, optional\n",
    "        Number of layers in the MLP. Defaults to 2.\n",
    "    mlp_input_norm : bool, optional\n",
    "        Whether to apply input normalization in the MLP. Defaults to False.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim,\n",
    "        hid_dim,\n",
    "        out_dim,\n",
    "        n_layers=2,\n",
    "        dropout=0.2,\n",
    "        input_dropout=0.2,\n",
    "        mlp_num_layers=2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            AllSetLayer(\n",
    "                in_dim=in_dim,\n",
    "                hid_dim=hid_dim,\n",
    "                out_dim=hid_dim,\n",
    "                dropout=dropout,\n",
    "                input_dropout=input_dropout,\n",
    "                mlp_num_layers=mlp_num_layers,\n",
    "                mlp_layer_norm=\"ln\",\n",
    "                mlp_num_layers=2,\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        for _ in range(n_layers - 1):\n",
    "            layers.append(\n",
    "                AllSetLayer(\n",
    "                    in_dim=hid_dim,\n",
    "                    hid_dim=hid_dim,\n",
    "                    out_dim=hid_dim,\n",
    "                    dropout=dropout,\n",
    "                    input_dropout=input_dropout,\n",
    "                    mlp_num_layers=mlp_num_layers,\n",
    "                    mlp_layer_norm=\"ln\",\n",
    "                    mlp_num_layers=2,\n",
    "                )\n",
    "            )\n",
    "        self.layers = torch.nn.ModuleList(layers)\n",
    "        self.linear = torch.nn.Linear(hid_dim, out_dim)\n",
    "\n",
    "    def forward(self, x_0, incidence_1):\n",
    "        \"\"\"\n",
    "        Forward computation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input features.\n",
    "        edge_index : torch.Tensor\n",
    "            Edge list (of size (2, |E|)).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Output prediction.\n",
    "        \"\"\"\n",
    "        # cidx = edge_index[1].min()\n",
    "        # edge_index[1] -= cidx\n",
    "        # reversed_edge_index = torch.stack(\n",
    "        #     [edge_index[1], edge_index[0]], dim=0)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x_0 = layer(x_0, incidence_1)\n",
    "        pooled_x = torch.max(x_0, dim=0)[0]\n",
    "        return torch.sigmoid(self.linear(pooled_x))[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model, the loss, and an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_dim, out_dim = 64, 1\n",
    "\n",
    "# Define the model\n",
    "model = AllSetNN(\n",
    "    in_dim=channels_node,\n",
    "    hid_dim=hid_dim,\n",
    "    out_dim=out_dim,\n",
    "    n_layers=1,\n",
    "    mlp_num_layers=1,\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer and loss\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T16:14:59.046068930Z",
     "start_time": "2023-06-01T16:14:59.037648626Z"
    }
   },
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "x_0_train, x_0_test = train_test_split(x_0s, test_size=test_size, shuffle=False)\n",
    "incidence_1_train, incidence_1_test = train_test_split(\n",
    "    incidence_1_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "y_train, y_test = train_test_split(ys, test_size=test_size, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell performs the training, looping over the network for a low amount of epochs. We keep training minimal for the purpose of rapid testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T16:15:01.683216142Z",
     "start_time": "2023-06-01T16:15:00.727075750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 274.8839\n",
      "Epoch: 2 loss: 274.6125\n",
      "Epoch: 3 loss: 274.6125\n",
      "Epoch: 4 loss: 274.6125\n",
      "Epoch: 5 loss: 274.6125\n",
      "Epoch: 6 loss: 274.6125\n",
      "Epoch: 7 loss: 274.6125\n",
      "Epoch: 8 loss: 274.6125\n",
      "Epoch: 9 loss: 274.6125\n",
      "Epoch: 10 loss: 274.6125\n",
      "Test_loss: 529.0000\n",
      "Epoch: 11 loss: 274.6125\n",
      "Epoch: 12 loss: 274.6125\n",
      "Epoch: 13 loss: 274.6125\n",
      "Epoch: 14 loss: 274.6125\n",
      "Epoch: 15 loss: 274.6125\n",
      "Epoch: 16 loss: 274.6125\n",
      "Epoch: 17 loss: 274.6125\n",
      "Epoch: 18 loss: 274.6125\n",
      "Epoch: 19 loss: 274.6125\n",
      "Epoch: 20 loss: 274.6125\n",
      "Test_loss: 529.0000\n",
      "Epoch: 21 loss: 274.6125\n",
      "Epoch: 22 loss: 274.6125\n",
      "Epoch: 23 loss: 274.6125\n",
      "Epoch: 24 loss: 274.6125\n",
      "Epoch: 25 loss: 274.6125\n",
      "Epoch: 26 loss: 274.6125\n",
      "Epoch: 27 loss: 274.6125\n",
      "Epoch: 28 loss: 274.6125\n",
      "Epoch: 29 loss: 274.6125\n",
      "Epoch: 30 loss: 274.6125\n",
      "Test_loss: 529.0000\n",
      "Epoch: 31 loss: 274.6125\n",
      "Epoch: 32 loss: 274.6125\n",
      "Epoch: 33 loss: 274.6125\n",
      "Epoch: 34 loss: 274.6125\n",
      "Epoch: 35 loss: 274.6125\n",
      "Epoch: 36 loss: 274.6125\n",
      "Epoch: 37 loss: 274.6125\n",
      "Epoch: 38 loss: 274.6125\n",
      "Epoch: 39 loss: 274.6125\n",
      "Epoch: 40 loss: 274.6125\n",
      "Test_loss: 529.0000\n",
      "Epoch: 41 loss: 274.6125\n",
      "Epoch: 42 loss: 274.6125\n",
      "Epoch: 43 loss: 274.6125\n",
      "Epoch: 44 loss: 274.6125\n",
      "Epoch: 45 loss: 274.6125\n",
      "Epoch: 46 loss: 274.6125\n",
      "Epoch: 47 loss: 274.6125\n",
      "Epoch: 48 loss: 274.6125\n",
      "Epoch: 49 loss: 274.6125\n",
      "Epoch: 50 loss: 274.6125\n",
      "Test_loss: 529.0000\n"
     ]
    }
   ],
   "source": [
    "test_interval = 10\n",
    "num_epochs = 50\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    for x_0, incidence_1, y in zip(x_0_train, incidence_1_train, y_train):\n",
    "        x_0 = torch.tensor(x_0)\n",
    "        x_0, incidence_1, y = (\n",
    "            x_0.float().to(device),\n",
    "            incidence_1.float().to(device),\n",
    "            torch.tensor(y, dtype=torch.float).to(device),\n",
    "        )\n",
    "        opt.zero_grad()\n",
    "        # Extract edge_index from sparse incidence matrix\n",
    "        # edge_index, _ = to_edge_index(incidence_1)\n",
    "        y_hat = model(x_0, incidence_1)\n",
    "        loss = loss_fn(y_hat, y)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            for x_0, incidence_1, y in zip(x_0_test, incidence_1_test, y_test):\n",
    "                x_0 = torch.tensor(x_0)\n",
    "                x_0, incidence_1, y = (\n",
    "                    x_0.float().to(device),\n",
    "                    incidence_1.float().to(device),\n",
    "                    torch.tensor(y, dtype=torch.float).to(device),\n",
    "                )\n",
    "                y_hat = model(x_0, incidence_1)\n",
    "                loss = loss_fn(y_hat, y)\n",
    "\n",
    "            print(f\"Test_loss: {loss:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidence_1.values = torch.Tensor(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(crow_indices=tensor([   0,   10,   22,   34,   46,   60,   70,   82,\n",
       "                              94,  104,  112,  122,  136,  144,  158,  170,\n",
       "                             178,  192,  204,  218,  234,  244,  256,  270,\n",
       "                             284,  294,  304,  318,  326,  336,  352,  366,\n",
       "                             376,  386,  396,  408,  418,  428,  442,  452,\n",
       "                             464,  474,  484,  498,  508,  520,  530,  540,\n",
       "                             554,  570,  580,  596,  606,  620,  630,  640,\n",
       "                             652,  666,  676,  686,  700,  712,  728,  734,\n",
       "                             748,  762,  774,  788,  804,  812,  824,  834,\n",
       "                             848,  860,  874,  888,  902,  916,  926,  934,\n",
       "                             942,  952,  962,  976,  988, 1000, 1010, 1022,\n",
       "                            1038, 1048, 1062, 1076, 1086, 1098, 1108, 1120,\n",
       "                            1130, 1142, 1154, 1168, 1178, 1190, 1202, 1212,\n",
       "                            1224, 1238, 1248, 1264, 1274, 1290, 1306, 1320,\n",
       "                            1330, 1342, 1356, 1368, 1380, 1392, 1404, 1416,\n",
       "                            1426, 1432, 1446, 1460, 1472, 1484, 1496, 1508,\n",
       "                            1522, 1534, 1544, 1560, 1572, 1584, 1598, 1610,\n",
       "                            1622, 1630, 1642, 1656, 1670, 1684, 1694, 1706,\n",
       "                            1720, 1734, 1748, 1758, 1774, 1784, 1796, 1806,\n",
       "                            1822, 1834, 1844, 1858, 1870, 1886, 1898, 1912,\n",
       "                            1926, 1938, 1950, 1964, 1978, 1988, 2000, 2012,\n",
       "                            2024, 2038, 2050, 2060, 2074, 2086, 2098, 2108,\n",
       "                            2120, 2134, 2144, 2156, 2172, 2182, 2196, 2208,\n",
       "                            2220, 2228, 2240, 2250, 2262, 2274, 2284, 2296,\n",
       "                            2312, 2322, 2334, 2344, 2356, 2368, 2382, 2392,\n",
       "                            2404, 2418, 2432, 2444, 2454, 2464, 2480, 2492,\n",
       "                            2502, 2516, 2528, 2538, 2550, 2560, 2572, 2584,\n",
       "                            2594, 2604, 2616, 2628, 2642, 2652, 2664, 2674,\n",
       "                            2686, 2698, 2712, 2724, 2736, 2748, 2758, 2768,\n",
       "                            2778, 2790, 2802, 2814, 2826, 2840, 2854, 2866,\n",
       "                            2876, 2888, 2900, 2910, 2920, 2932, 2944, 2954,\n",
       "                            2964, 2974, 2982, 2990, 3000]),\n",
       "       col_indices=tensor([   0,    1,    2,  ..., 1247, 1248, 1249]),\n",
       "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]), size=(252, 1250),\n",
       "       nnz=3000, layout=torch.sparse_csr)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incidence_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = torch.randn(3, 10)\n",
    "incidence_1 = torch.tensor([[1, 1, 0], [1, 1, 1], [0, 1, 1]], dtype=torch.float32)\n",
    "\n",
    "in_dim = 10\n",
    "hid_dim = 40\n",
    "out_out = 10\n",
    "layer = AllSetLayer(in_dim, hid_dim, out_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5924, 0.9794, 0.0289, 0.0000, 0.1268, 0.1217, 1.2585, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0090, 0.0000, 0.4814, 0.8803, 0.0000, 0.0000, 0.6687, 0.0000,\n",
       "         0.9917],\n",
       "        [0.0000, 0.0000, 0.0000, 0.1937, 0.0000, 0.0000, 0.0000, 1.3111, 0.0000,\n",
       "         0.1433]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(x_0, incidence_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
